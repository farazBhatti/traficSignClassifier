{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241f748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "import keras_metrics\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ce7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = valid_datagen.flow_from_directory(\n",
    "        'dataset/test',\n",
    "        target_size=(150, 150),\n",
    "        color_mode= \"grayscale\",\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        color_mode= \"grayscale\",\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        'dataset/validate',\n",
    "        target_size=(150, 150),\n",
    "        color_mode= \"grayscale\",\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099669b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(150,150)))\n",
    "model.add(Dense(150, input_dim=22500, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\",keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=800 // 32,\n",
    "        epochs=500,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=200 // 32)\n",
    "model.save_weights('first_try.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "pred = model.predict_generator(test_generator)#,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41150709",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.argmax(pred, axis=-1)\n",
    "val_trues = test_generator.classes\n",
    "cm = confusion_matrix(val_trues, val_preds)\n",
    "cm\n",
    "print(val_trues)\n",
    "print(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ad6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_generator.class_indices.keys()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recall, f1_score, _ = precision_recall_fscore_support(val_trues, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c220ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dcc7e15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cb0b577db04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mquery_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/test/00004/00719_00002.ppm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainKeypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(trainDescriptors.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orb' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "  \n",
    "     \n",
    "# Read the query image as query_img\n",
    "# and train image This query image\n",
    "# is what you need to find in train image\n",
    "# Save it in the same directory\n",
    "# with the name image.jpg \n",
    "train_img = cv2.imread('dataset/train/00010/00530_00000.ppm')\n",
    "query_img = cv2.imread('dataset/test/00004/00719_00002.ppm')\n",
    "  \n",
    "trainKeypoints, m = orb.detectAndCompute(query_img,None)\n",
    "\n",
    "# print(trainDescriptors.shape)\n",
    "print(\"query descriptors\" , m.shape)\n",
    "    \n",
    "# Convert it to grayscale\n",
    "query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY)\n",
    "train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Initialize the ORB detector algorithm\n",
    "orb = cv2.ORB_create()\n",
    "  \n",
    "# Now detect the keypoints and compute\n",
    "# the descriptors for the query image\n",
    "# and train image\n",
    "queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
    "trainKeypoints, trainDescriptors = orb.detectAndCompute(train_img_bw,None)\n",
    "\n",
    " \n",
    "# Initialize the Matcher for matching\n",
    "# the keypoints and then match the\n",
    "# keypoints\n",
    "matcher = cv2.BFMatcher()\n",
    "matches = matcher.match(queryDescriptors,trainDescriptors)\n",
    "  \n",
    "# draw the matches to the final image\n",
    "# containing both the images the drawMatches()\n",
    "# function takes both images and keypoints\n",
    "# and outputs the matched query image with\n",
    "# its train image\n",
    "final_img = cv2.drawMatches(query_img, queryKeypoints,\n",
    "train_img, trainKeypoints, matches[:20],None)\n",
    "  \n",
    "final_img = cv2.resize(final_img, (1000,650))\n",
    " \n",
    "# Show the final image\n",
    "cv2.imshow(\"Matches\", final_img)\n",
    "cv2.waitKey(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8740a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00004\n",
      "01186_00002.ppm\n",
      "dataset/train/00004/01186_00002.ppm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'orb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1615fe81d710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mKeypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDescriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img_bw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDescriptors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtrainDescriptors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDescriptors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orb' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trainKeyposints = []\n",
    "trainDescriptors = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for folder in os.listdir(\"dataset/train/\"):\n",
    "    print(folder)\n",
    "    \n",
    "    for file in os.listdir(\"dataset/train/\" + folder + \"/\"):\n",
    "        print(file)\n",
    "        name = 'dataset/train/'+ folder +\"/\" + file\n",
    "        print(name)\n",
    "        train_img = cv2.imread('dataset/train/'+ folder +\"/\" + file)\n",
    "        if train_img is None:\n",
    "            print(\"no image\")\n",
    "        cv2.imshow(\"imgt\",train_img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        \n",
    "        train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "        Keypoints, Descriptors = orb.detectAndCompute(train_img_bw,None)\n",
    "        print(Descriptors)\n",
    "        trainDescriptors.append(Descriptors.flatten())\n",
    "        trainKeyposints.append(Keypoints)\n",
    "        labels.append(int(folder))\n",
    "        print(len(Descriptors.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# #Create KNN Classifier\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# #Train the model using the training sets\n",
    "# knn.fit(trainDescriptors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(trainDescriptors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e16fb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bf7be596b9f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqueryDescriptors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "query_img = cv2.imread('dataset/test/00004/00719_00002.ppm')\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "# Convert it to grayscale\n",
    "query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  \n",
    "# Initialize the ORB detector algorithm\n",
    "orb = cv2.ORB_create()\n",
    "  \n",
    "# Now detect the keypoints and compute\n",
    "# the descriptors for the query image\n",
    "# and train image\n",
    "queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
    "\n",
    "print(len(queryDescriptors))\n",
    "\n",
    "\n",
    "clf.predict([queryDescriptors.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(queryDescriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(trainDescriptors)):\n",
    "    print(len(trainDescriptors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c566ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
