{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "import keras_metrics\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ce7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = valid_datagen.flow_from_directory(\n",
    "        'dataset/test',\n",
    "        target_size=(150, 150),\n",
    "        color_mode= \"grayscale\",\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        color_mode= \"grayscale\",\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        'dataset/validate',\n",
    "        target_size=(150, 150),\n",
    "        color_mode= \"grayscale\",\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099669b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(150,150)))\n",
    "model.add(Dense(150, input_dim=22500, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\",keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=800 // 32,\n",
    "        epochs=500,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=200 // 32)\n",
    "model.save_weights('first_try.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "pred = model.predict_generator(test_generator)#,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41150709",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.argmax(pred, axis=-1)\n",
    "val_trues = test_generator.classes\n",
    "cm = confusion_matrix(val_trues, val_preds)\n",
    "cm\n",
    "print(val_trues)\n",
    "print(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ad6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_generator.class_indices.keys()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recall, f1_score, _ = precision_recall_fscore_support(val_trues, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c220ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "  \n",
    "     \n",
    "# Read the query image as query_img\n",
    "# and train image This query image\n",
    "# is what you need to find in train image\n",
    "# Save it in the same directory\n",
    "# with the name image.jpg \n",
    "train_img = cv2.imread('dataset/test/00004/00719_00002.ppm')\n",
    "query_img = cv2.imread('dataset/train/00004/01017_00001.ppm')\n",
    "\n",
    "# print(trainDescriptors.shape)\n",
    "\n",
    "    \n",
    "# Convert it to grayscale\n",
    "query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY)\n",
    "train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Initialize the ORB detector algorithm\n",
    "orb = cv2.ORB_create()\n",
    "  \n",
    "# Now detect the keypoints and compute\n",
    "# the descriptors for the query image\n",
    "# and train image\n",
    "queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
    "trainKeypoints, trainDescriptors = orb.detectAndCompute(train_img_bw,None)\n",
    "print(\"query descriptors\" , queryDescriptors.shape)\n",
    "print(\"train Descriptor shape  = \", trainDescriptors.shape)\n",
    " \n",
    "# Initialize the Matcher for matching\n",
    "# the keypoints and then match the\n",
    "# keypoints\n",
    "matcher = cv2.BFMatcher()\n",
    "matches = matcher.match(queryDescriptors,trainDescriptors)\n",
    "  \n",
    "# draw the matches to the final image\n",
    "# containing both the images the drawMatches()\n",
    "# function takes both images and keypoints\n",
    "# and outputs the matched query image with\n",
    "# its train image\n",
    "final_img = cv2.drawMatches(query_img, queryKeypoints,\n",
    "train_img, trainKeypoints, matches[:20],None)\n",
    "  \n",
    "final_img = cv2.resize(final_img, (1000,650))\n",
    " \n",
    "# Show the final image\n",
    "cv2.imshow(\"Matches\", final_img)\n",
    "cv2.waitKey(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "737a7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00004\n",
      "00002\n",
      "00006\n",
      "00001\n",
      "00007\n",
      "00008\n",
      "00003\n",
      "00005\n",
      "00010\n",
      "00009\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn import svm \n",
    "import numpy as np \n",
    "from skimage.feature import hog \n",
    "trainKeyposints = []\n",
    "trainDescriptors = []\n",
    "labels = []\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "hog_train_data = [] \n",
    "# hog = cv2.HOGDescriptor()\n",
    "\n",
    "\n",
    "for folder in os.listdir(\"dataset/train/\"):\n",
    "    print(folder)\n",
    "    \n",
    "    for file in os.listdir(\"dataset/train/\" + folder + \"/\"):\n",
    "#         print(file)\n",
    "        name = 'dataset/train/'+ folder +\"/\" + file\n",
    "#         print(name)\n",
    "        train_img = cv2.imread('dataset/train/'+ folder +\"/\" + file)\n",
    "        if train_img is None:\n",
    "            print(\"no image\")\n",
    "#         cv2.imshow(\"imgt\",train_img)\n",
    "#         cv2.waitKey(0)\n",
    "        dim = (32, 32)\n",
    "  \n",
    "        # resize image\n",
    "        img = cv2.resize(train_img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#         h = hog.compute(img)\n",
    "#         winStride = (8,8)\n",
    "#         padding = (8,8)\n",
    "#         locations = ((10,20),)\n",
    "#         hist = hog.compute(img,winStride,padding,locations)\n",
    "\n",
    " \n",
    "#         convert BGR image to gray-scale \n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "#         tune these hyper-parameters according to your needs \n",
    "#         here fd is the new feature descriptor for your image \n",
    "        fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
    "#         for visualisation of the hog features \n",
    "#         plt.imshow(hog_img) \n",
    "        hog_train_data.append(fd) \n",
    "        \n",
    "#         train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "#         Keypoints, Descriptors = orb.detectAndCompute(train_img_bw,None)\n",
    "#         if Descriptors is not None:\n",
    "#             print(Descriptors.shape)\n",
    "#             trainDescriptors.append(Descriptors)#.flatten())\n",
    "#             trainKeyposints.append(Keypoints)\n",
    "        labels.append(int(folder))\n",
    "# #             print(len(Descriptors.flatten()))\n",
    "#         else: \n",
    "#             print(\"NONE Descriptor\")\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83044bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert it to np array \n",
    "hog_train_data = np.array(hog_train_data) \n",
    "#one-vs-all SVM linear classifier \n",
    "lin_clf = svm.LinearSVC() \n",
    "#train the classifier using new hog features and training labels \n",
    "lin_clf.fit(hog_train_data, labels) \n",
    "#likewise extract features for your testing data and test the classifier using the new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc0430c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('dataset/test/00004/00719_00002.ppm')\n",
    "if train_img is None:\n",
    "    print(\"no image\")\n",
    "#         cv2.imshow(\"imgt\",train_img)\n",
    "#         cv2.waitKey(0)\n",
    "dim = (32, 32)\n",
    "\n",
    "# resize image\n",
    "img = cv2.resize(test_img, dim, interpolation = cv2.INTER_AREA)\n",
    "fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred = lin_clf.predict([fd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a92fa1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# kmeans = KMeans(n_clusters = 200, n_init=10, init='random')\n",
    "# gg=[item for sublist in trainDescriptors for item in sublist]\n",
    "# kmeans.fit(gg)#vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# clf = svm.SVC(decision_function_shape='ovo')\n",
    "# clf.fit(trainDescriptors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query_img = cv2.imread('dataset/test/00004/00719_00002.ppm')\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "# # Convert it to grayscale\n",
    "# query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  \n",
    "# # Initialize the ORB detector algorithm\n",
    "# orb = cv2.ORB_create()\n",
    "  \n",
    "# # Now detect the keypoints and compute\n",
    "# # the descriptors for the query image\n",
    "# # and train image\n",
    "# queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
    "\n",
    "# print(len(queryDescriptors))\n",
    "\n",
    "\n",
    "# clf.predict([queryDescriptors.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2 as cv\n",
    "# img = cv.imread('dataset/train/00004/01017_00001.ppm')\n",
    "# gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "# sift = cv.SIFT_create()\n",
    "# kp = sift.detect(gray,None)\n",
    "# img=cv.drawKeypoints(gray,kp,img)\n",
    "# cv.imwrite('sift_keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(trainDescriptors)):\n",
    "    print(len(trainDescriptors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume shape of train_data: (no. of samples) x (32*32*3) where 32x32x3 is the dimension of a BGR image \n",
    "import cv2 \n",
    "from sklearn import svm \n",
    "import numpy as np \n",
    "from skimage.feature import hog \n",
    "import matplotlib.pyplot as plt \n",
    " \n",
    "hog_train_data = [] \n",
    "for i in range(len(train_data)): \n",
    "    img = train_data[i].reshape(32, 32, 3) \n",
    "\t#convert BGR image to gray-scale \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\t#tune these hyper-parameters according to your needs \n",
    "\t#here fd is the new feature descriptor for your image \n",
    "    fd, hog_img = hog(img, orientations=10, pixels_per_cell=(12, 12), cells_per_block=(8, 8), feature_vector=True, visualise=True, block_norm='L2-Hys') \n",
    "\t#for visualisation of the hog features \n",
    "\tplt.imshow(hog_img) \n",
    "    hog_train_data.append(fd) \n",
    "#convert it to np array \n",
    "hog_train_data = np.array(hog_train_data) \n",
    "#one-vs-all SVM linear classifier \n",
    "lin_clf = svm.LinearSVC() \n",
    "#train the classifier using new hog features and training labels \n",
    "lin_clf.fit(hog_train_data, train_label) \n",
    "#likewise extract features for your testing data and test the classifier using the new features \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
